{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "from logistic_regression import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 subsets of 111 training examples with labels\n",
      "Total 1110 training examples and labels\n"
     ]
    }
   ],
   "source": [
    "dataset_root_directory = './dataset'\n",
    "full_dataset = DataLoader.load_full_dataset(dataset_root_directory)\n",
    "print('%d subsets of %d training examples with labels' % (len(full_dataset), len(full_dataset[0][0])))\n",
    "print('Total %d training examples and labels' % (len(full_dataset)*len(full_dataset[0][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and learn a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 86.75675675675674\n",
      "Training Accuracy = 86.757 %\n",
      "\n",
      "=====Model Summary=====\n",
      "w0 = [0.04729453]\n",
      "\n",
      "w of size (64, 1) :\n",
      "array([[-0.00017858],\n",
      "       [ 0.00719516],\n",
      "       [ 0.01357879],\n",
      "       [ 0.00577427],\n",
      "       [ 0.02376583],\n",
      "       [ 0.07107198],\n",
      "       [ 0.01014586],\n",
      "       [ 0.01618142],\n",
      "       [ 0.03662329],\n",
      "       [-0.01094573],\n",
      "       [ 0.0521205 ],\n",
      "       [ 0.00543148],\n",
      "       [ 0.0094478 ],\n",
      "       [ 0.07003225],\n",
      "       [ 0.00489671],\n",
      "       [-0.02263623],\n",
      "       [ 0.03234231],\n",
      "       [ 0.02862491],\n",
      "       [ 0.00438958],\n",
      "       [-0.00900111],\n",
      "       [-0.00526394],\n",
      "       [-0.02526586],\n",
      "       [-0.01513025],\n",
      "       [ 0.01133964],\n",
      "       [ 0.02345222],\n",
      "       [ 0.00527371],\n",
      "       [-0.00931745],\n",
      "       [ 0.00806537],\n",
      "       [ 0.03951118],\n",
      "       [-0.00307993],\n",
      "       [-0.02989851],\n",
      "       [ 0.00098481],\n",
      "       [ 0.03202586],\n",
      "       [-0.00446742],\n",
      "       [-0.02888178],\n",
      "       [-0.01797764],\n",
      "       [-0.01489359],\n",
      "       [-0.03668074],\n",
      "       [-0.01723574],\n",
      "       [-0.01993071],\n",
      "       [-0.0188092 ],\n",
      "       [-0.00170911],\n",
      "       [-0.0971274 ],\n",
      "       [-0.03673489],\n",
      "       [-0.00110908],\n",
      "       [ 0.01218841],\n",
      "       [ 0.01113517],\n",
      "       [-0.0206173 ],\n",
      "       [ 0.01472703],\n",
      "       [-0.04444963],\n",
      "       [-0.03246154],\n",
      "       [-0.02379431],\n",
      "       [ 0.02774582],\n",
      "       [-0.01419604],\n",
      "       [-0.03235892],\n",
      "       [ 0.00440439],\n",
      "       [-0.01158626],\n",
      "       [-0.03269139],\n",
      "       [ 0.04051352],\n",
      "       [ 0.02619754],\n",
      "       [-0.00826436],\n",
      "       [-0.02185749],\n",
      "       [ 0.0020406 ],\n",
      "       [ 0.00705125]])\n",
      "Training Accuracy = 86.757 %\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(M=input_vector_size)\n",
    "\n",
    "# Train the model on the full dataset\n",
    "model.learn(full_dataset, report_acc=True)\n",
    "\n",
    "# Model parameters and stats\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 64) testing examples\n",
      "(111, 1) testing labels\n",
      "9 subsets of 111 training examples with labels\n",
      "Total 999 training examples and labels\n",
      "\n",
      "Test Accuracy = 88.288 %\n",
      "\n",
      "=====Result( True label , Predicted lalue )=====\n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 6.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 6.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 6.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n"
     ]
    }
   ],
   "source": [
    "# The above trained model can now classify unseen test data in the future\n",
    "\n",
    "# Since we do not have unseen test data, we will take a part of training data as test data and \n",
    "# test a newly trained model on remaining data as training data \n",
    "\n",
    "# To generate test data, we split the training data\n",
    "train_dataset, test_attrs, test_labels = DataLoader.load_with_test_data(\n",
    "                                                         dataset_root_directory,\n",
    "                                                         split_ratio=0.1)\n",
    "print(test_attrs.shape, 'testing examples')\n",
    "print(test_labels.shape, 'testing labels')\n",
    "print('%d subsets of %d training examples with labels' % (len(train_dataset), len(train_dataset[0][0])))\n",
    "print('Total %d training examples and labels' % (len(train_dataset)*len(train_dataset[0][0])))\n",
    "\n",
    "\n",
    "model = LogisticRegression(M=input_vector_size)\n",
    "model.learn(train_dataset)\n",
    "predicted_labels, accuracy = model.classify(test_attrs, true_labels=test_labels)\n",
    "\n",
    "print('\\nTest Accuracy = %.3f %%' % accuracy)\n",
    "print('\\n=====Result( True label , Predicted lalue )=====')\n",
    "for values in np.dstack((test_labels, predicted_labels)):\n",
    "    #print('True label = ', values[0][0], 'Predicted label = ', values[0][1]) \n",
    "    print('(',values[0][0], ',', values[0][1], ')', end=' ')\n",
    "    if values[0][0] != values[0][1]:\n",
    "        print(' <--------Incorrect', end=' ')\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
