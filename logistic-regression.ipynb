{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "from logistic_regression import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 subsets of 111 training examples with labels\n",
      "Total 1110 training examples and labels\n"
     ]
    }
   ],
   "source": [
    "dataset_root_directory = './dataset'\n",
    "full_dataset = DataLoader.load_full_dataset(dataset_root_directory)\n",
    "print('%d subsets of %d training examples with labels' % (len(full_dataset), len(full_dataset[0][0])))\n",
    "print('Total %d training examples and labels' % (len(full_dataset)*len(full_dataset[0][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and learn a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 86.75675675675674\n",
      "Training Accuracy = 86.757 %\n",
      "\n",
      "=====Model Summary=====\n",
      "w0 = [0.04729453]\n",
      "\n",
      "w of size (64, 1) :\n",
      "array([[-0.00017858],\n",
      "       [ 0.00719516],\n",
      "       [ 0.01357879],\n",
      "       [ 0.00577427],\n",
      "       [ 0.02376583],\n",
      "       [ 0.07107198],\n",
      "       [ 0.01014586],\n",
      "       [ 0.01618142],\n",
      "       [ 0.03662329],\n",
      "       [-0.01094573],\n",
      "       [ 0.0521205 ],\n",
      "       [ 0.00543148],\n",
      "       [ 0.0094478 ],\n",
      "       [ 0.07003225],\n",
      "       [ 0.00489671],\n",
      "       [-0.02263623],\n",
      "       [ 0.03234231],\n",
      "       [ 0.02862491],\n",
      "       [ 0.00438958],\n",
      "       [-0.00900111],\n",
      "       [-0.00526394],\n",
      "       [-0.02526586],\n",
      "       [-0.01513025],\n",
      "       [ 0.01133964],\n",
      "       [ 0.02345222],\n",
      "       [ 0.00527371],\n",
      "       [-0.00931745],\n",
      "       [ 0.00806537],\n",
      "       [ 0.03951118],\n",
      "       [-0.00307993],\n",
      "       [-0.02989851],\n",
      "       [ 0.00098481],\n",
      "       [ 0.03202586],\n",
      "       [-0.00446742],\n",
      "       [-0.02888178],\n",
      "       [-0.01797764],\n",
      "       [-0.01489359],\n",
      "       [-0.03668074],\n",
      "       [-0.01723574],\n",
      "       [-0.01993071],\n",
      "       [-0.0188092 ],\n",
      "       [-0.00170911],\n",
      "       [-0.0971274 ],\n",
      "       [-0.03673489],\n",
      "       [-0.00110908],\n",
      "       [ 0.01218841],\n",
      "       [ 0.01113517],\n",
      "       [-0.0206173 ],\n",
      "       [ 0.01472703],\n",
      "       [-0.04444963],\n",
      "       [-0.03246154],\n",
      "       [-0.02379431],\n",
      "       [ 0.02774582],\n",
      "       [-0.01419604],\n",
      "       [-0.03235892],\n",
      "       [ 0.00440439],\n",
      "       [-0.01158626],\n",
      "       [-0.03269139],\n",
      "       [ 0.04051352],\n",
      "       [ 0.02619754],\n",
      "       [-0.00826436],\n",
      "       [-0.02185749],\n",
      "       [ 0.0020406 ],\n",
      "       [ 0.00705125]])\n",
      "Training Accuracy = 86.757 %\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(M=input_vector_size)\n",
    "\n",
    "# Train the model on the full dataset\n",
    "model.learn(full_dataset, report_acc=True)\n",
    "\n",
    "# Model parameters and stats\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 64) testing examples\n",
      "(111, 1) testing labels\n",
      "9 subsets of 111 training examples with labels\n",
      "Total 999 training examples and labels\n",
      "\n",
      "Test Accuracy = 88.288 %\n",
      "\n",
      "=====Result( True label , Predicted lalue )=====\n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 6.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 6.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 6.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 5.0 )  <--------Incorrect \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 5.0 , 5.0 ) \n",
      "( 6.0 , 6.0 ) \n",
      "( 5.0 , 5.0 ) \n"
     ]
    }
   ],
   "source": [
    "# The above trained model can now classify unseen test data in the future\n",
    "\n",
    "# Since we do not have unseen test data, we will take a part of training data as test data and \n",
    "# test a newly trained model on remaining data as training data \n",
    "\n",
    "# To generate test data, we split the training data\n",
    "train_dataset, test_attrs, test_labels = DataLoader.load_with_test_data(\n",
    "                                                         dataset_root_directory,\n",
    "                                                         split_ratio=0.1)\n",
    "print(test_attrs.shape, 'testing examples')\n",
    "print(test_labels.shape, 'testing labels')\n",
    "print('%d subsets of %d training examples with labels' % (len(train_dataset), len(train_dataset[0][0])))\n",
    "print('Total %d training examples and labels' % (len(train_dataset)*len(train_dataset[0][0])))\n",
    "\n",
    "\n",
    "test_model = LogisticRegression(M=input_vector_size)\n",
    "test_model.learn(train_dataset)\n",
    "predicted_labels, accuracy = test_model.classify(test_attrs, true_labels=test_labels)\n",
    "\n",
    "print('\\nTest Accuracy = %.3f %%' % accuracy)\n",
    "print('\\n=====Result( True label , Predicted lalue )=====')\n",
    "for values in np.dstack((test_labels, predicted_labels)):\n",
    "    #print('True label = ', values[0][0], 'Predicted label = ', values[0][1]) \n",
    "    print('(',values[0][0], ',', values[0][1], ')', end=' ')\n",
    "    if values[0][0] != values[0][1]:\n",
    "        print(' <--------Incorrect', end=' ')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Seperability experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is not linearly seperable\n",
      "==========Experiment Summary==========\n",
      "Total No. of Data points = 1110\n",
      "Class 5 points above hyperplane = 493\n",
      "Class 5 points below hyperplane = 58\n",
      "Class 6 points below hyperplane = 494\n",
      "Class 6 points above hyperplane = 65\n"
     ]
    }
   ],
   "source": [
    "X, y = DataLoader.load_merged_dataset(dataset_root_directory)\n",
    "\n",
    "# Use the model with which the whole data was trained\n",
    "below_hyperplane, above_hyperplane = model.do_experiment(X, true_labels=y)\n",
    "\n",
    "# Get count of points of each class above and below hyperplane\n",
    "class5_below = below_hyperplane.count(5.0)\n",
    "class6_below = below_hyperplane.count(6.0)\n",
    "class5_above = above_hyperplane.count(5.0)\n",
    "class6_above = above_hyperplane.count(6.0)\n",
    "\n",
    "# Check if data is linear seperable\n",
    "if 0 in [class5_below, class5_above] and 0 in [class6_below, class6_above]:\n",
    "    print('The data is linearly seperable')\n",
    "else:\n",
    "    print('The data is not linearly seperable')\n",
    "\n",
    "print('='*10 + 'Experiment Summary' + 10*'=')\n",
    "print('Total No. of Data points =', len(below_hyperplane) + len(above_hyperplane))\n",
    "print('Class 5 points above hyperplane =', class5_above)\n",
    "print('Class 5 points below hyperplane =', class5_below)\n",
    "print('Class 6 points below hyperplane =', class6_below)\n",
    "print('Class 6 points above hyperplane =', class6_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
